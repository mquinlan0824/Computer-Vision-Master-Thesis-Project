{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b904a9b0-8353-4666-8e8b-ecbfc987053b",
   "metadata": {},
   "source": [
    "## **Model Tuning: Transfer Learning with Efficient Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99796cdc-8b93-43cb-a96d-1a21f21adf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7d96b-c5f7-4061-ac31-96496d9f8583",
   "metadata": {},
   "source": [
    "## **Load image dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b58e59c-b17f-4471-8ce5-c86342b20455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose day or night dataframe for reference\n",
    "#infile = 'day_df.pkl'\n",
    "#infile = 'night_df.pkl'\n",
    "path = '/home/ubuntu/michael/my_pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c2b35-eb82-49a0-9ba1-d765e2129764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set reference dataframe\n",
    "sample_df = pd.read_pickle(path + infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cde31-4a79-4bb4-bfe8-84ffcecc2f02",
   "metadata": {},
   "source": [
    "## **Set source directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b6c52c-d60a-48a4-80f9-bf07de42a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access day images only\n",
    "train_dir = '/home/ubuntu/michael/day/train'\n",
    "val_dir = '/home/ubuntu/michael/day/validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec042694-3490-4daf-8852-956feddb0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access night images only\n",
    "#train_dir = '/home/ubuntu/michael/night/train'\n",
    "#val_dir = '/home/ubuntu/michael/night/validate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388443cb-e52f-44db-bcb1-726ba355f34f",
   "metadata": {},
   "source": [
    "## **Loading images from directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb317dbe-bacc-49d1-84ba-25e8e8651aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca60685-8de1-4fac-a69d-fb828c308daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input size of images based on model specs\n",
    "img_size = (224, 224)\n",
    "img_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a75b394-0c00-4b97-9553-f0c1d757685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data generator and augment training images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, \n",
    "                                   width_shift_range = 0.2, height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bfa8e1-51f5-4a61-936b-d5a21f772b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation data generator and rescale validation images\n",
    "valid_datagen = ImageDataGenerator(rescale = 1.0 / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d94edb-1b0c-44a5-bd61-a777bd406970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare trainging iterator\n",
    "train_it = train_datagen.flow_from_directory(directory = train_dir, classes = ['nofog', 'fog'], class_mode = 'binary', # train_iterator\n",
    "                    batch_size = 64, target_size=img_size) # batch size is number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd904587-5d66-4ea8-9e11-a86a0baa0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_it.classes\n",
    "class_indices = train_it.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fd3803-4213-4502-94a5-4eaf02730738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare validation iterator\n",
    "valid_it = valid_datagen.flow_from_directory(directory = val_dir, classes = ['nofog', 'fog'], class_mode = 'binary', # validation_iterator\n",
    "                    batch_size = 16, target_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d51c7af7-88f2-4ecc-ab65-a944a469c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = valid_it.classes\n",
    "class_indices = valid_it.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb8487-fc71-45d9-b0be-b0de06852e9f",
   "metadata": {},
   "source": [
    "## **Load Efficient net model as convoutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4384f66-9208-4204-934e-34b862c3ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained efficient net model and weights for convolution\n",
    "conv_base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape = img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c94905-6ac2-4501-9bba-07a8cad53b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to false so weights are retained\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad5e74-89ce-4940-b16e-e9ba985bef20",
   "metadata": {},
   "source": [
    "## **Add classifier on top of convolutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d56b63-234f-440a-bf4b-d6227edfb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classification portion of model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3db03ff4-f5e8-4f45-b767-84738bcf721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 7, 7, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 1280)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11520)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              11797504  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 15,848,100\n",
      "Trainable params: 11,798,529\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view classification architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af97248-b131-4e88-9fdc-58e44a1bb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer =  RMSprop(lr = 1e-6, decay=1e-6), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee494b6-fdfa-4add-b9c2-f4148e83b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 0, \n",
    "                                      patience=15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bef855-620e-4611-a9c6-14acff5eedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint path\n",
    "outputFolder = '/home/ubuntu/michael/model_output/EfficientNet/'\n",
    "#outputFolder = '/home/ubuntu/michael/model_output/EfficientNet/day/'\n",
    "#outputFolder = '/home/ubuntu/michael/model_output/EfficientNet/night/'\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d77f5076-1bc6-4fb6-9fc6-bc1110730eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chekpoint path and add checkpoints\n",
    "checkpoint_path = outputFolder + 'EfficientNet_model.hdf5'\n",
    "\n",
    "# add checkpoints\n",
    "cp = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', mode = 'min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0ac0f87-d5c4-4078-8f75-df04e3f383ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with train itertor and use valid_it as a validation dataset during training\n",
    "history = model.fit(train_it, steps_per_epoch = len(train_it), # @ of steps is the number of batches per epoch\n",
    "                    validation_data = valid_it, validation_steps = len(valid_it), \n",
    "                    epochs = 3, verbose = 1, callbacks=[es, cp]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a86529f0-fd21-4b68-aef8-68cf9fb422cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(valid_it, steps=len(valid_it), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef264e18-07c2-459c-bb30-60b75f59d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model validation score\n",
    "with open(outputFolder + 'EfficientNet_score.pkl', 'wb') as f:pickle.dump(score, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "226a2cc9-7977-42da-ae78-532b8d06e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access training and validation loss and accuracy data\n",
    "loss_values = history.history['loss']\n",
    "acc_values = history.history['acc']\n",
    "valLoss_values = history.history['val_loss']\n",
    "valAccuracy_values = history.history['val_acc']\n",
    "\n",
    "# create dataframe to store accuracy and loss data\n",
    "history_df = pd.DataFrame()\n",
    "history_df['Training Loss'] = history.history['loss']\n",
    "history_df['Training Accuracy'] = history.history['acc']\n",
    "history_df['Validation Loss'] = history.history['val_loss']\n",
    "history_df['Validation Accuracy'] = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a73c83db-263c-44f1-8f70-d406a24cd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_pickle(outputFolder + 'EfficientNet_history.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
