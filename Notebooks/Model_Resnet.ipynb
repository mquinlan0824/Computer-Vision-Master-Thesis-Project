{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c6c99f-2b32-467e-b93d-c215e4c6241d",
   "metadata": {},
   "source": [
    "## **Model Tuning: Transfer Learning with Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99796cdc-8b93-43cb-a96d-1a21f21adf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3a155-ce9a-4160-9127-45b3c54a8c96",
   "metadata": {},
   "source": [
    "## **Load image dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb1171b-55d0-4654-92e0-399f9937048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose day or night dataframe for reference\n",
    "infile = 'day_df.pkl'\n",
    "#infile = 'night_df.pkl'\n",
    "path = '/home/ubuntu/michael/my_pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02cd4be6-303c-4482-8cb3-ebbc549ee521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set reference dataframe\n",
    "sample_df = pd.read_pickle(path + infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32ac5c-17ac-49b6-9f2d-0f82c6fcf296",
   "metadata": {},
   "source": [
    "## **Set source directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383c3a68-98d3-4b92-8e91-948301d767a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access day images only\n",
    "train_dir = '/home/ubuntu/michael/day/train'\n",
    "val_dir = '/home/ubuntu/michael/day/validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e475cc98-bd7d-45eb-b883-f8555f27b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access night images only\n",
    "#train_dir = '/home/ubuntu/michael/night/train'\n",
    "#val_dir = '/home/ubuntu/michael/night/validate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4563a9a-0e1e-4db1-9080-5af867d66002",
   "metadata": {},
   "source": [
    "## **Loading images with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb317dbe-bacc-49d1-84ba-25e8e8651aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca60685-8de1-4fac-a69d-fb828c308daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image size and shape\n",
    "img_size = (224, 224)\n",
    "img_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d69c4-40dd-4bd0-9170-8166dcc2be77",
   "metadata": {},
   "source": [
    "## **Load images from directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6de712-c34b-4e71-88c7-52b2266a8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "datagen = ImageDataGenerator(rescale = 1.0 / 255.0) #scale pixel values to be in the range of 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89391322-3728-45a8-8453-ffa834ad3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include 'out-of-the-box' image augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, \n",
    "                                   width_shift_range = 0.2, height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "702c5751-62f8-4083-a8b3-3b4ecc02335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare training iterator\n",
    "train_it = datagen.flow_from_directory(directory = train_dir, classes = ['nofog', 'fog'], class_mode = 'binary', \n",
    "                    batch_size = 64, target_size = img_size) \n",
    "# flip classes due to alphabetical order; fog would be 0 since it preceeds nofog in the alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ae581d-fe36-48cd-811c-c8252a9f381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign class names and indices\n",
    "class_names = train_it.classes # lists all assignments of images [0 = nofog; 1 = fog]\n",
    "class_indices = train_it.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8109262a-f16b-49dd-8994-3d0b61341979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare validation iterator\n",
    "valid_it = datagen.flow_from_directory(directory = val_dir, classes = ['nofog', 'fog'], class_mode = 'binary', \n",
    "                    batch_size = 16, target_size = img_size)\n",
    "# flip classes due to alphabetical order; fog would be 0 since it preceeds nofog in the alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cfa1a5c-4925-4000-b6dc-baf91ef71fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = valid_it.classes\n",
    "class_indices = valid_it.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69ecd2-a249-4ae1-964e-9147ce7371f2",
   "metadata": {},
   "source": [
    "## **Load Resent model as convoutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73fc6aea-fb68-4303-93a3-a4ad14f14df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained base model Resnet\n",
    "conv_base = ResNet50(input_shape = img_shape, include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c94905-6ac2-4501-9bba-07a8cad53b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze base layers\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee28e47-8a90-4a3b-84b7-498dec342b46",
   "metadata": {},
   "source": [
    "## **Add classifier on top of convolutional base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2415954-4507-499a-817f-0f5f0276834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classification model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e06780-b9f2-423a-b876-7a9ae1b9b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 126,350,209\n",
      "Trainable params: 102,762,497\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view classification architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9098de8-0f8f-4c48-8906-b5a99957a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer =  RMSprop(lr = 1e-4), \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23b5a52b-3128-4066-ae54-0a566d7ea534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, \n",
    "                                      patience=15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9ff800-610d-49b2-aad0-5ab289070efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose day or night output folder\n",
    "outputFolder = '/home/ubuntu/michael/model_output/Resnet/'\n",
    "#outputFolder = '/home/ubuntu/michael/model_output/Resnet/day/'\n",
    "#outputFolder = '/home/ubuntu/michael/model_output/Resnet/night/'\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e23b810-e3c7-494d-9a49-e124d2e02ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chekpoint path and add checkpoints\n",
    "checkpoint_path = outputFolder + 'Resnet_model.hdf5'\n",
    "\n",
    "# create a model checkpoint when condtions are met\n",
    "cp = ModelCheckpoint(checkpoint_path, monitor = 'val_acc', mode = 'max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0ac0f87-d5c4-4078-8f75-df04e3f383ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with train itertor and use valid_it as a validation dataset during training\n",
    "history = model.fit(train_it, steps_per_epoch = len(train_it), \n",
    "                    validation_data = valid_it, \n",
    "                    validation_steps = len(valid_it), \n",
    "                    epochs = 300, verbose = 1, callbacks=[es, cp]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a86529f0-fd21-4b68-aef8-68cf9fb422cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(valid_it, steps=len(valid_it), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef06c80-ab55-4d64-9b4b-8bb64cedd895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model validation score\n",
    "with open(outputFolder + 'Resnet_score.pkl', 'wb') as f:pickle.dump(score, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "226a2cc9-7977-42da-ae78-532b8d06e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access training and loss values from history object\n",
    "loss_values = history.history['loss']\n",
    "acc_values = history.history['acc']\n",
    "valLoss_values = history.history['val_loss']\n",
    "valAccuracy_values = history.history['val_acc']\n",
    "\n",
    "# create a dataframe to store training accuracy and loss values\n",
    "history_df = pd.DataFrame()\n",
    "history_df['Training Loss'] = history.history['loss']\n",
    "history_df['Training Accuracy'] = history.history['acc']\n",
    "history_df['Validation Loss'] = history.history['val_loss']\n",
    "history_df['Validation Accuracy'] = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a73c83db-263c-44f1-8f70-d406a24cd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save accuracy and loss values to a dataframe\n",
    "history_df.to_pickle(outputFolder + 'Resnet_history.pkl') #/home/ubuntu/michael/my_historys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
